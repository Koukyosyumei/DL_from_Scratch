{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "attention.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "4GuWtgJPjZDg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "import random\n",
        "from sklearn.utils import shuffle"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9d6yoC-l8_yJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "from matplotlib import pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NZwr3MK9oWlJ",
        "colab_type": "code",
        "outputId": "0c781ac0-5525-4034-a0ac-eebad91bf081",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 157
        }
      },
      "source": [
        "!pip install mxnet"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: mxnet in /usr/local/lib/python3.6/dist-packages (1.6.0)\n",
            "Requirement already satisfied: requests<3,>=2.20.0 in /usr/local/lib/python3.6/dist-packages (from mxnet) (2.23.0)\n",
            "Requirement already satisfied: graphviz<0.9.0,>=0.8.1 in /usr/local/lib/python3.6/dist-packages (from mxnet) (0.8.4)\n",
            "Requirement already satisfied: numpy<2.0.0,>1.16.0 in /usr/local/lib/python3.6/dist-packages (from mxnet) (1.18.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.20.0->mxnet) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.20.0->mxnet) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.20.0->mxnet) (2.9)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.20.0->mxnet) (2020.4.5.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "47oDhfm2oVC-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import mxnet as mx\n",
        "from mxnet import gluon\n",
        "from mxnet.gluon import nn\n",
        "from mxnet.gluon import rnn\n",
        "from mxnet import autograd as ag\n",
        "import mxnet.ndarray as F"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oHhdOR8fnxPe",
        "colab_type": "text"
      },
      "source": [
        "## 前処理"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7fUSo8pvj-cj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 事前にGoogle Driveをマウントして以下の場所にdate.txtを格納しておく\n",
        "file_path = \"nlp_sample.txt\"\n",
        "\n",
        "input_date = [] # 変換前の日付データ\n",
        "output_date = [] # 変換後の日付データ\n",
        "\n",
        "# date.txtを1行ずつ読み込んで変換前と変換後に分割して、inputとoutputで分ける\n",
        "with open(file_path, \"r\") as f:\n",
        "  date_list = f.readlines()\n",
        "  for date in date_list:\n",
        "    date = date[:-1]\n",
        "    input_date.append(date.split(\"_\")[0])\n",
        "    output_date.append(\"_\" + date.split(\"_\")[1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x9jjdU6_xZ2B",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "46eb5679-8c74-434a-eefc-185d81645afc"
      },
      "source": [
        "print(\"num of sentence: \", len(input_date))"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "num of sentence:  50000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PLylCFU-xTQo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_date = input_date[:500]\n",
        "output_date = output_date[:500]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jrqWHKTwkBa9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# inputとoutputの系列の長さを取得\n",
        "# すべて長さが同じなので、0番目の要素でlenを取ってます\n",
        "input_len = len(input_date[0]) # 29\n",
        "output_len = len(output_date[0]) # 10"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6NlAvl_qkbtK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# date.txtで登場するすべての文字にIDを割り当てる\n",
        "char2id = {c:i for i, c in\\\n",
        "            enumerate(set(list(\"\".join((input_date + output_date)))))}\n",
        "\n",
        "input_data = [] # ID化された変換前日付データ\n",
        "output_data = [] # ID化された変換後日付データ\n",
        "for input_chars, output_chars in zip(input_date, output_date):\n",
        "  input_data.append([char2id[c] for c in input_chars])\n",
        "  output_data.append([char2id[c] for c in output_chars])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kg5cFPddlHn3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 7:3でtrainとtestに分ける\n",
        "train_x, test_x, train_y, test_y = train_test_split(input_data, output_data, train_size= 0.7)\n",
        "\n",
        "# データをバッチ化するための関数を定義\n",
        "def train2batch(input_data, output_data, batch_size=100):\n",
        "    input_batch = []\n",
        "    output_batch = []\n",
        "    input_shuffle, output_shuffle = shuffle(input_data, output_data)\n",
        "    for i in range(0, len(input_data), batch_size):\n",
        "      input_batch.append(input_shuffle[i:i+batch_size])\n",
        "      output_batch.append(output_shuffle[i:i+batch_size])\n",
        "    return input_batch, output_batch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1h05lv3an17B",
        "colab_type": "text"
      },
      "source": [
        "## パラメータ設定"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tBcpTC2ymuvD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "embedding_dim = 200\n",
        "hidden_dim = 128\n",
        "BATCH_NUM = 100\n",
        "vocab_size = len(char2id)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0UQwdMtg5_fw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "epoch = 100"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1zdW_hqSn73T",
        "colab_type": "text"
      },
      "source": [
        "## Encoderの設定"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vwb8Q3hCojmT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Encoder(gluon.Block):\n",
        "  def __init__(self, vocab_size, embedding_dim, hidden_dim, num_layers=1, batch_size=100, **kwargs):\n",
        "      super(Encoder, self).__init__(**kwargs)\n",
        "      with self.name_scope():\n",
        "          self.hidden_dim = hidden_dim\n",
        "          self.num_layers = num_layers\n",
        "          self.batch_size = batch_size\n",
        "\n",
        "          self.word_embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
        "          self.gru = rnn.GRU(hidden_dim, input_size=embedding_dim, layout=\"NTC\")\n",
        "\n",
        "  def forward(self, sequence):\n",
        "      embedding = self.word_embeddings(sequence)\n",
        "      # state.size() = (num_layers, batch_size, num_hidden)\n",
        "      begin_state = mx.nd.random.uniform(shape=(self.num_layers, self.batch_size, self.hidden_dim))\n",
        "      hs, h = self.gru(embedding, begin_state)\n",
        "      return hs, h"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tgmJPFkYse_V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class AttentionDecoder(gluon.Block):\n",
        "  def __init__(self, vocab_size, embedding_dim, hidden_dim, batch_size, **kwargs):\n",
        "      super(AttentionDecoder, self).__init__(**kwargs)\n",
        "      with self.name_scope():\n",
        "          self.hidden_dim = hidden_dim\n",
        "          self.batch_size = batch_size\n",
        "\n",
        "          self.word_embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
        "          self.gru = rnn.GRU(hidden_dim, input_size=embedding_dim, layout=\"NTC\")\n",
        "          #各系列のGRUの隠れ層とAttention層で計算したコンテ\n",
        "          # hidden_dim*2としているのはキストベクトルをtorch.catでつなぎ合わせることで長さが２倍になるため\n",
        "          #self.hidden2linear = nn.Dense(vocab_size, in_units=hidden_dim * 2)\n",
        "          self.hidden2linear = nn.Dense(vocab_size, in_units=hidden_dim * 2, flatten=False)\n",
        "\n",
        "  def forward(self, sequence, hs, h):\n",
        "      embedding = self.word_embeddings(sequence)\n",
        "      output, state = self.gru(embedding, h)\n",
        "\n",
        "      # Attention層\n",
        "      # hs.size() = ([batch_size, 29, hidden_dim])\n",
        "      # output.size() = ([batch_size, 10, hidden_dim])\n",
        "\n",
        "      # bmmを使ってEncoder側の出力(hs)とDecoder側の出力(output)を\n",
        "      # batchごとまとめて行列計算するために、Decoder側のoutputを\n",
        "      # batchを固定して転置行列を取る\n",
        "      # t_output.size() = ([batch_size, hidden_dim, 10])\n",
        "      \n",
        "      t_output = mx.ndarray.transpose(output, axes=(0,2,1))\n",
        "      # s.size() = ([batch_size, 29, 10])\n",
        "      s = mx.ndarray.linalg.gemm2(hs, t_output)\n",
        "      \n",
        "      # 列方向で和\n",
        "      # attention_weight.size() = ([100, 29, 10])\n",
        "      attention_weight = mx.nd.softmax(s, axis=1)\n",
        "\n",
        "      # コンテキストベクトルをまとめるために入れ物を用意\n",
        "      # c.size() = ([batch_size, 1, hidden_dim])\n",
        "      \n",
        "      c = mx.ndarray.zeros((self.batch_size, 1, self.hidden_dim))\n",
        "\n",
        "      \n",
        "      # 各層（Decoder側のGRU層は生成文字列が10文字なので10個ある）\n",
        "      #におけるattention weightを取り出してforループ内でコンテキスト\n",
        "      # ベクトルを１つずつ作成する\n",
        "      # バッチ方向はまとめて計算できたのでバッチはそのまま\n",
        "      \n",
        "      for i in range(attention_weight.shape[2]): # 10回ループ\n",
        "\n",
        "        # attention_weight[:,:,i].size() = ([batch_size, 29])\n",
        "        # i番目のGRU層に対するattention weightを取り出すが、テンソルの\n",
        "        # サイズをhsと揃えるためにunsqueezeする\n",
        "        # unsq_weight.size() = ([batch_size, 29, 1])\n",
        "        unsq_weight = attention_weight[:,:,i].reshape(attention_weight.shape[0],\\\n",
        "                                              attention_weight.shape[1], 1)\n",
        "\n",
        "        # hsの各ベクトルをattention weightで重み付けする\n",
        "        # weighted_hs.size() = ([batch_size, 29, hidden_num])\n",
        "        weighted_hs = hs * unsq_weight \n",
        "        \n",
        "        # attention weightで重み付けされた各hsのベクトルをすべて足し合わせて\n",
        "        # コンテキストベクトルを作成\n",
        "        # weight_sum.size() = ([batch_size, 1, hidden_num])\n",
        "        weight_sum = mx.nd.sum(weighted_hs, axis=1).reshape(self.batch_size,\\\n",
        "                                                                1, self.hidden_dim)\n",
        "        \n",
        "        # c.size() = ([batch_size, i, hidden_num])\n",
        "        c = mx.ndarray.concat(c, weight_sum, dim=1)\n",
        "      \n",
        "      # 箱として用意したzero要素が残っているのでスライスして削除\n",
        "      # output.size() = ([batch_size, 10, hidden_dim*2])\n",
        "      \n",
        "      c = c[:,1:,:]\n",
        "      output = mx.nd.concat(output, c, dim=2)\n",
        "      output = self.hidden2linear(output)\n",
        "\n",
        "      return output, state, attention_weight"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bUb29cypsfKK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "encoder = Encoder(vocab_size, embedding_dim, hidden_dim)\n",
        "attn_decoder = AttentionDecoder(vocab_size, embedding_dim, hidden_dim, BATCH_NUM)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LHMw6oeksfOg",
        "colab_type": "code",
        "outputId": "2ae0c673-f569-4245-b7a8-bebbddf8206c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "encoder.summary"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method Block.summary of Encoder(\n",
              "  (word_embeddings): Embedding(59 -> 200, float32)\n",
              "  (gru): GRU(200 -> 128, NTC)\n",
              ")>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vx5Zy2Bgn62U",
        "colab_type": "code",
        "outputId": "ba8415e6-6288-4768-f85c-d343635689bb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "source": [
        "attn_decoder.summary"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method Block.summary of AttentionDecoder(\n",
              "  (word_embeddings): Embedding(59 -> 200, float32)\n",
              "  (gru): GRU(200 -> 128, NTC)\n",
              "  (hidden2linear): Dense(256 -> 59, linear)\n",
              ")>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N3-UDfwI5XOn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# set the context on GPU is available otherwise CPU\n",
        "ctx = [mx.gpu() if mx.test_utils.list_gpus() else mx.cpu()]\n",
        "encoder.initialize(mx.init.Xavier(magnitude=2.24), ctx=ctx)\n",
        "encoder_trainer = gluon.Trainer(encoder.collect_params(), 'sgd', {'learning_rate': 0.03})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dQak_4HQ5lGt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# set the context on GPU is available otherwise CPU\n",
        "ctx = [mx.gpu() if mx.test_utils.list_gpus() else mx.cpu()]\n",
        "attn_decoder.initialize(mx.init.Xavier(magnitude=2.24), ctx=ctx)\n",
        "attn_decoder_trainer = gluon.Trainer(attn_decoder.collect_params(), 'sgd', {'learning_rate': 0.03})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zZ2liFckfpuj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 損失関数\n",
        "criterion = gluon.loss.SoftmaxCrossEntropyLoss()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ty8cBOrH9Oda",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_x = np.array(train_x)\n",
        "train_y = np.array(train_y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZZKK7lLZ8z7i",
        "colab_type": "code",
        "outputId": "3a11ff8d-538a-45da-b0cf-2c025622eed0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "print(np.array(train_x).shape)\n",
        "print(np.array(train_y).shape)"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(350, 29)\n",
            "(350, 11)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jx_4c6h-67-9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data = mx.io.NDArrayIter(train_x, train_y, BATCH_NUM, shuffle=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cpoDoOVA5xpe",
        "colab_type": "code",
        "outputId": "0abd1fde-1a30-43ed-b784-40ef2088aa16",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 192
        }
      },
      "source": [
        "loss_log = []\n",
        "for i in range(epoch):\n",
        "  train_data.reset()\n",
        "  for batch in train_data:\n",
        "      data = gluon.utils.split_and_load(batch.data[0], ctx_list=ctx, batch_axis=0)\n",
        "      label = gluon.utils.split_and_load(batch.label[0], ctx_list=ctx, batch_axis=0)\n",
        "\n",
        "      with ag.record():\n",
        "          for x, y in zip(data, label):\n",
        "              hs, h = encoder(x)\n",
        "\n",
        "              # Attention Decoderのインプット\n",
        "              source = y[:, :-1]\n",
        "              # Attention Decoderの正解データ\n",
        "              target = y[:, 1:]\n",
        "\n",
        "              decoder_output, _, attention_weight= attn_decoder(source, hs, h)\n",
        "              #output = attn_decoder(source, hs, h)\n",
        "\n",
        "              loss = []\n",
        "              for j in range(decoder_output.shape[1]):\n",
        "                  loss.append(criterion(decoder_output[:, j, :], target[:, j]))\n",
        "\n",
        "              loss_sum = sum(loss)\n",
        "              loss_sum.backward()\n",
        "\n",
        "      encoder_trainer.step(batch.data[0].shape[0])\n",
        "      attn_decoder_trainer.step(batch.data[0].shape[0])\n",
        "\n",
        "  loss_sum_sum = sum(loss_sum).asnumpy()[0]\n",
        "  loss_log.append(loss_sum_sum)\n",
        "  if i % 10 == 0:\n",
        "      print(\"epoch_{i} loss: {loss}\".format(i=i, loss=loss_sum_sum))"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch_0 loss: 3755.5595703125\n",
            "epoch_10 loss: 1972.5611572265625\n",
            "epoch_20 loss: 1464.1612548828125\n",
            "epoch_30 loss: 1333.322021484375\n",
            "epoch_40 loss: 1201.8514404296875\n",
            "epoch_50 loss: 1138.8641357421875\n",
            "epoch_60 loss: 1106.321533203125\n",
            "epoch_70 loss: 1076.081298828125\n",
            "epoch_80 loss: 1050.4949951171875\n",
            "epoch_90 loss: 1033.99755859375\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O09LIHtrxAey",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        },
        "outputId": "035aeff9-ad7d-48a9-b470-7fec393e1ab8"
      },
      "source": [
        "plt.title(\"attention_loss.png\")\n",
        "plt.plot(loss_log)"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f7c2e5a96d8>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4wF1Lowc0XEg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}